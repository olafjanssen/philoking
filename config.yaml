kafka:
  brokers:
    - "localhost:9092"
  topics:
    chat_messages: "chat-messages"
    chat_responses: "chat-responses"
    agent_input: "agent-input"
    agent_output: "agent-output"

web:
  host: "localhost"
  port: "8080"

agents:
  provider: "ollama"  # "ollama" or "openai"
  model: "llama2"     # Model name (e.g., llama2, codellama, mistral)
  ollama_url: "http://localhost:11434"
  llm_api_key: ""     # Set via LLM_API_KEY environment variable
  llm_url: "https://api.openai.com/v1/chat/completions"
  
  # Agents configuration
  agents:
    - id: "llm-agent-1"
      name: "LLM Agent 1"
      type: "llm"
      response_chance: 0.8
      enabled: true
      description: "First LLM-powered agent"
      
    - id: "llm-agent-2"
      name: "LLM Agent 2"
      type: "llm"
      response_chance: 0.6
      enabled: true
      description: "Second LLM-powered agent"
      
      