kafka:
  brokers:
    - "localhost:9092"
  topics:
    chat_messages: "chat-messages"
    chat_responses: "chat-responses"
    agent_input: "agent-input"
    agent_output: "agent-output"

web:
  host: "localhost"
  port: "8080"

agents:
  provider: "ollama"  # "ollama" or "openai"
  model: "llama2"     # Model name (e.g., llama2, codellama, mistral)
  ollama_url: "http://localhost:11434"
  llm_api_key: ""     # Set via LLM_API_KEY environment variable
  llm_url: "https://api.openai.com/v1/chat/completions"
  
  # Natural conversation agents configuration
  natural_agents:
    - id: "agent-1"
      name: "Agent 1"
      response_chance: 0.8
      enabled: true
      description: "First conversation agent"
      
    - id: "agent-2"
      name: "Agent 2"
      response_chance: 0.7
      enabled: true
      description: "Second conversation agent"
      
    - id: "agent-3"
      name: "Agent 3"
      response_chance: 0.6
      enabled: true
      description: "Third conversation agent"
      
    - id: "agent-4"
      name: "Agent 4"
      response_chance: 0.5
      enabled: true
      description: "Fourth conversation agent"